\section{Introduction}
\subsection{Overview}

In this study we have attempted to harness the power of deep learning techniques in order to analyse and understand the content of street images. More specifically, our aim was to create a program that, provided with an image of an urban environment, will be able to accurately identify and classify the different elements that make up the scene. In computer vision terms this task is called image segmentation. In image segmentation (also referred to as dense prediction) the goal is to break down an image at pixel level into areas (segments) that correspond to different classes of objects. In our case the type of these classes correspond to elements usually found in the urban landscape, such as roads, buildings, persons, cars, trees etc. A tool that allows to perform this task could have several practical applications. For example, it could be used to enhance vehicle safety by being able to promptly alert drivers when a pedestrian or bicycle is detected in the projected path of a car. It could also be useful in creating applications that promote vehicle autonomy, where a car is able to navigate its environment and trace a safe path ahead without the need of human input. 

Semantic segmentation is typically performed using deep learning methods, particularly convolutional neural networks (CNNs) and their variants as well as more recent attention-based models. In this study we have deployed the freely available Cityscapes dataset \cite{DBLP:journals/corr/CordtsORREBFRS16} which is a state-of-the-art dataset used for this particular type of analysis. We have presented the characteristics of the dataset and the metrics that are used in evaluating and ranking of models. We have created and trained our own models, with distinct characteristics and architectures and have evaluated their performance. We have performed a parameter sweep analysis to find the set of hyperparameters that give us the best results. We have found that a model with more complex, attention-based architecture has given us the best results. Finally we have used our model in inference mode to display the results that are obtained when images unrelated to the training dataset are passed through the model.

